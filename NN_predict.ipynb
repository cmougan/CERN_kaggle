{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from NN_files.gbfeatures import GradientBoostingFeatureGenerator\n",
    "from sklearn.externals import joblib\n",
    "import random\n",
    "import os\n",
    "\n",
    "# os.path.isfile(fname)\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "class ReadDataset(Dataset):\n",
    "    \"\"\"CERN kaagle dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, for_test=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (str): Path to the csv file with the students data.\n",
    "\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file).drop(columns=\"BUTTER\")\n",
    "        self.df.columns = self.df.columns.str.replace(\" \", \"\")\n",
    "\n",
    "        try:\n",
    "            self.df = self.df.drop(columns=[\"Unnamed:0\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Target\n",
    "        self.target = \"signal\"\n",
    "        # If we read test, not load the target\n",
    "        if for_test == False:\n",
    "            # Save target and predictors\n",
    "            self.X = self.df.drop(self.target, axis=1)\n",
    "            self.y = self.df[self.target]\n",
    "\n",
    "        else:\n",
    "            self.X = self.df\n",
    "\n",
    "        # Create features\n",
    "        self.X = self.transform(self.X)\n",
    "        self.X = self.feature_engineering(self.X)\n",
    "\n",
    "\n",
    "        # If the scaler does not exist create it\n",
    "        if os.path.isfile(\"output/scaler.save\") == False:\n",
    "            self.scaler = MinMaxScaler()\n",
    "            self.scaler = self.scaler.fit(self.X)\n",
    "            ## Save scaler to be later used on the prediction\n",
    "            joblib.dump(self.scaler, \"output/scaler.save\")\n",
    "        # If the scale exist, load it\n",
    "        else:\n",
    "            self.scaler = joblib.load(\"output/scaler.save\")\n",
    "        ## Scale data\n",
    "        self.X = pd.DataFrame(self.scaler.transform(self.X), columns=self.X.columns)\n",
    "        print('---')\n",
    "        print(self.X.shape)\n",
    "        ## GB features\n",
    "        sample_size = int(self.X.shape[0]/10)\n",
    "        if os.path.isfile(\"output/gbFreat.save\") == False:\n",
    "            self.gb_feat = GradientBoostingFeatureGenerator()\n",
    "            self.gb_feat.fit(self.X.head(sample_size),self.y.head(sample_size))\n",
    "            joblib.dump(self.scaler, \"output/gbFeat.save\")\n",
    "        else:\n",
    "            self.gb_feat = joblib.load(\"output/gbFeat.save\")\n",
    "        self.X = pd.DataFrame(self.gb_feat.transform(self.X))\n",
    "\n",
    "        print(self.X.shape)\n",
    "\n",
    "\n",
    "    def transform(self, df):\n",
    "        # Did not work\n",
    "        df[\"Kst_892_0_cosThetaH_arc\"] = np.arccos(df[\"Kst_892_0_cosThetaH\"])\n",
    "        df[\"Kst_892_0_cosThetaH_arc_sin\"] = np.sin(df.Kst_892_0_cosThetaH_arc)\n",
    "\n",
    "        df[\"Kplu_pXKst_892costheta\"] = df[\"Kplus_P\"] * df[\"Kst_892_0_cosThetaH\"]\n",
    "\n",
    "        df[\"momentum_by_shortest_dist\"] = df[\"Kplus_P\"] / df[\"Kplus_IP_OWNPV\"]\n",
    "\n",
    "        df[\"momentum_sum\"] = df[\"B_PT\"] + df[\"Kplus_P\"] + df[\"gamma_PT\"]\n",
    "\n",
    "        # Worked individually\n",
    "        df[\"Kplu_p_div_Kst_892costheta\"] = df[\"Kplus_P\"] / df[\"Kst_892_0_cosThetaH\"]\n",
    "\n",
    "        # ETA (estimated time of arrival) inversions -- worked\n",
    "        df[\"Kplus_ETA_inv\"] = 1 / df[\"Kplus_ETA\"]\n",
    "        df[\"piminus_ETA_inv\"] = 1 / df[\"piminus_ETA\"]\n",
    "\n",
    "        # Momentum\n",
    "\n",
    "        df[\"total_mom_2\"] = df[\"B_PT\"] ** 2 + df[\"gamma_PT\"] ** 2 + df[\"Kplus_P\"] ** 2\n",
    "        df[\"total_mom_sum\"] = df[\"B_PT\"] + df[\"gamma_PT\"] + df[\"Kplus_P\"]\n",
    "\n",
    "        # All mom ratios worked together\n",
    "        df[\"mom_rat_1\"] = df[\"B_PT\"] / df[\"Kplus_P\"]\n",
    "        df[\"mom_rat_2\"] = df[\"B_PT\"] / df[\"gamma_PT\"]\n",
    "\n",
    "        df[\"mom_rat_3\"] = df[\"gamma_PT\"] / df[\"B_PT\"]\n",
    "        df[\"mom_rat_4\"] = df[\"gamma_PT\"] / df[\"Kplus_P\"]\n",
    "\n",
    "        df[\"mom_rat_5\"] = df[\"Kplus_P\"] / df[\"B_PT\"]\n",
    "        df[\"mom_rat_6\"] = df[\"Kplus_P\"] / df[\"gamma_PT\"]\n",
    "\n",
    "        df[\"ThetaH\"] = np.arccos(df[\"Kst_892_0_cosThetaH\"])\n",
    "\n",
    "        df[\"Kplus_P_x\"] = df[\"Kplus_P\"] * np.sin(df[\"ThetaH\"])\n",
    "        df[\"Kplus_P_y\"] = df[\"Kplus_P\"] * np.cos(df[\"ThetaH\"])\n",
    "\n",
    "        df[\"mom_consev1\"] = df[\"gamma_PT\"] ** 2 + df[\"Kplus_P\"] ** 2 - df[\"B_PT\"] ** 2\n",
    "        df[\"mom_consev1_1\"] = ((df[\"gamma_PT\"] + df[\"Kplus_P\"])) ** 2 - df[\"B_PT\"] ** 2\n",
    "\n",
    "        # B meson ratios\n",
    "        df[\"mesB_ratio_1\"] = df[\"B_FDCHI2_OWNPV\"] / df[\"B_IPCHI2_OWNPV\"]\n",
    "        df[\"mesB_ratio_2\"] = df[\"B_FDCHI2_OWNPV\"] / df[\"B_PT\"]\n",
    "\n",
    "        df[\"mesB_ratio_3\"] = df[\"B_IPCHI2_OWNPV\"] / df[\"B_PT\"]\n",
    "        df[\"mesB_ratio_4\"] = df[\"B_IPCHI2_OWNPV\"] / df[\"B_PT\"]\n",
    "\n",
    "        df[\"mesB_ratio_5\"] = df[\"B_PT\"] / df[\"B_IPCHI2_OWNPV\"]\n",
    "        df[\"mesB_ratio_6\"] = df[\"B_PT\"] / df[\"B_FDCHI2_OWNPV\"]\n",
    "\n",
    "        # Neither Improved neither worst\n",
    "        df[\"kst_thetaH\"] = np.arccos(df.Kst_892_0_cosThetaH)  # * 180 / np.pi\n",
    "        df[\"kst_thetaH_sin\"] = np.sin(df[\"kst_thetaH\"])\n",
    "        df[\"kst_thetaH_cos\"] = np.cos(df[\"kst_thetaH\"])\n",
    "        df[\"kst_thetaH_sin_cos\"] = np.sin(df[\"kst_thetaH\"]) - np.cos(df[\"kst_thetaH\"])\n",
    "        df[\"kst_thetaH_tan\"] = np.tan(df[\"kst_thetaH\"])\n",
    "        df[\"kst_thetaH_exp\"] = np.exp(df[\"kst_thetaH\"])\n",
    "        df[\"kst_thetaH_exp_1\"] = np.exp(-df[\"kst_thetaH\"])\n",
    "\n",
    "        df[\"B_DIRA_OWNPV_angle\"] = np.arccos(df[\"B_DIRA_OWNPV\"])  # * 180 / np.pi\n",
    "        df[\"B_DIRA_OWNPV__cos\"] = np.cos(df[\"B_DIRA_OWNPV_angle\"])\n",
    "        df[\"B_DIRA_OWNPV__sin\"] = np.sin(df[\"B_DIRA_OWNPV_angle\"])\n",
    "        df[\"B_DIRA_OWNPV__tan\"] = np.tan(df[\"B_DIRA_OWNPV_angle\"])\n",
    "        df[\"B_DIRA_OWNPV__sin_cos\"] = np.sin(df[\"B_DIRA_OWNPV_angle\"]) - np.cos(\n",
    "            df[\"B_DIRA_OWNPV_angle\"]\n",
    "        )\n",
    "        df[\"B_DIRA_OWNPV_exp\"] = np.exp(df[\"B_DIRA_OWNPV_angle\"])\n",
    "        df[\"B_DIRA_OWNPV_exp_1\"] = np.exp(-df[\"B_DIRA_OWNPV_angle\"])\n",
    "\n",
    "        # Momentum multiplication\n",
    "        df[\"mom1_exp\"] = df[\"mom_rat_1\"] * df[\"B_DIRA_OWNPV_exp\"]\n",
    "        df[\"mom2_exp\"] = df[\"mom_rat_2\"] * df[\"B_DIRA_OWNPV_exp\"]\n",
    "        df[\"mom3_exp\"] = df[\"mom_rat_3\"] * df[\"B_DIRA_OWNPV_exp\"]\n",
    "        df[\"mom4_exp\"] = df[\"mom_rat_4\"] * df[\"B_DIRA_OWNPV_exp\"]\n",
    "        df[\"mom5_exp\"] = df[\"mom_rat_5\"] * df[\"B_DIRA_OWNPV_exp\"]\n",
    "        df[\"mom6_exp\"] = df[\"mom_rat_6\"] * df[\"B_DIRA_OWNPV_exp\"]\n",
    "        df[\"mom7_exp\"] = df[\"B_PT\"] * df[\"B_DIRA_OWNPV_exp\"]\n",
    "        df[\"mom8_exp\"] = df[\"Kplus_P\"] * df[\"B_DIRA_OWNPV_exp\"]\n",
    "        df[\"mom9_exp\"] = df[\"gamma_PT\"] * df[\"B_DIRA_OWNPV_exp\"]\n",
    "\n",
    "        df[\"mom11_exp\"] = df[\"mom_rat_1\"] * df[\"kst_thetaH\"]\n",
    "        df[\"mom22_exp\"] = df[\"mom_rat_2\"] * df[\"kst_thetaH\"]\n",
    "        df[\"mom33_exp\"] = df[\"mom_rat_3\"] * df[\"kst_thetaH\"]\n",
    "        df[\"mom44_exp\"] = df[\"mom_rat_4\"] * df[\"kst_thetaH\"]\n",
    "        df[\"mom55_exp\"] = df[\"mom_rat_5\"] * df[\"kst_thetaH\"]\n",
    "        df[\"mom66_exp\"] = df[\"mom_rat_6\"] * df[\"kst_thetaH\"]\n",
    "        df[\"mom77_exp\"] = df[\"B_PT\"] * df[\"kst_thetaH\"]\n",
    "        df[\"mom88_exp\"] = df[\"Kplus_P\"] * df[\"kst_thetaH\"]\n",
    "        df[\"mom99_exp\"] = df[\"gamma_PT\"] * df[\"kst_thetaH\"]\n",
    "\n",
    "        df[\"Kplus_ETA_2\"] = df[\"Kplus_ETA\"] ** 2\n",
    "        df[\"Kplus_ETA_exp\"] = np.exp(df[\"Kplus_ETA\"])\n",
    "        df[\"Kplus_ETA_theta\"] = df[\"Kplus_ETA\"] * df[\"kst_thetaH\"]\n",
    "        df[\"Kplus_ETA_div_theta\"] = df[\"Kplus_ETA\"] / df[\"kst_thetaH\"]\n",
    "        df[\"Kplus_ETA_theta_sin\"] = df[\"Kplus_ETA\"] * df[\"kst_thetaH_sin\"]\n",
    "        df[\"Kplus_ETA_theta_tan\"] = df[\"Kplus_ETA\"] * df[\"kst_thetaH_tan\"]\n",
    "\n",
    "        df[\"piminus_ETA_2\"] = df[\"piminus_ETA\"] ** 2\n",
    "        df[\"piminus_ETA_exp\"] = np.exp(df[\"piminus_ETA\"])\n",
    "        df[\"piminus_ETA_theta\"] = df[\"piminus_ETA\"] * df[\"kst_thetaH\"]\n",
    "        df[\"piminus_ETA_div_theta\"] = df[\"piminus_ETA\"] / df[\"kst_thetaH\"]\n",
    "        df[\"piminus_ETA_theta_sin\"] = df[\"piminus_ETA\"] * df[\"kst_thetaH_sin\"]\n",
    "        df[\"piminus_ETA_theta_tan\"] = df[\"piminus_ETA\"] * df[\"kst_thetaH_tan\"]\n",
    "\n",
    "        # Improves\n",
    "        df[\"Kplus_by_eta\"] = df[\"Kplus_P\"] / df[\"Kplus_ETA\"]\n",
    "\n",
    "        df[\"Kplus_piminus_by_eta\"] = df[\"Kplus_P\"] / df[\"piminus_ETA\"]\n",
    "\n",
    "        df[\"ETA_add\"] = df[\"Kplus_ETA\"] + df[\"piminus_ETA\"]\n",
    "        df[\"ETA_rest\"] = df[\"Kplus_ETA\"] - df[\"piminus_ETA\"]\n",
    "        df[\"ETA_mult\"] = df[\"Kplus_ETA\"] * df[\"piminus_ETA\"]\n",
    "        df[\"ETA_inv\"] = df[\"Kplus_ETA\"] / df[\"piminus_ETA\"]\n",
    "        df[\"ETA_inv1\"] = df[\"piminus_ETA\"] / df[\"Kplus_ETA\"]\n",
    "\n",
    "        df[\"Kplus_ETA_inv\"] = df[\"Kplus_ETA\"]\n",
    "        df[\"piminus_ETA_inv\"] = df[\"piminus_ETA\"]\n",
    "\n",
    "        df[\"ETA_add_inv\"] = df[\"Kplus_ETA_inv\"] + df[\"piminus_ETA_inv\"]\n",
    "        df[\"ETA_rest_inv\"] = df[\"Kplus_ETA_inv\"] - df[\"piminus_ETA_inv\"]\n",
    "        df[\"ETA_mult_inv\"] = df[\"Kplus_ETA_inv\"] * df[\"piminus_ETA_inv\"]\n",
    "        df[\"ETA_inv_inv\"] = df[\"Kplus_ETA_inv\"] / df[\"piminus_ETA_inv\"]\n",
    "        df[\"ETA_inv1_inv\"] = df[\"piminus_ETA_inv\"] / df[\"Kplus_ETA_inv\"]\n",
    "\n",
    "        self.df = df\n",
    "        return self.df\n",
    "\n",
    "    def feature_engineering(self, all_df):\n",
    "        \"\"\"\n",
    "        Features by david 05/11\n",
    "        \"\"\"\n",
    "\n",
    "        all_df.columns = [col.replace(\" \", \"\") for col in all_df.columns]\n",
    "        # cos -> sin transformation\n",
    "        all_df[\"Kst_892_0_sinThetaH\"] = np.sqrt(1 - all_df[\"Kst_892_0_cosThetaH\"] ** 2)\n",
    "        all_df[\"B_DIRA_OWNPV_sin\"] = np.sqrt(1 - all_df[\"B_DIRA_OWNPV\"] ** 2)\n",
    "        # x and y P components\n",
    "        all_df[\"Kplus_P_x\"] = all_df[\"Kplus_P\"] * all_df[\"Kst_892_0_sinThetaH\"]\n",
    "        all_df[\"Kplus_P_y\"] = all_df[\"Kplus_P\"] * all_df[\"Kst_892_0_cosThetaH\"]\n",
    "        all_df[\"Kplus_P_x0\"] = all_df[\"Kplus_P\"] * np.sin(all_df[\"Kplus_ETA\"])\n",
    "        all_df[\"Kplus_P_y0\"] = all_df[\"Kplus_P\"] * np.cos(all_df[\"Kplus_ETA\"])\n",
    "        all_df[\"pminus_P_x\"] = all_df[\"piminus_P\"] * all_df[\"Kst_892_0_sinThetaH\"]\n",
    "        all_df[\"pminus_P_y\"] = all_df[\"piminus_P\"] * all_df[\"Kst_892_0_cosThetaH\"]\n",
    "        all_df[\"pminus_P_x0\"] = all_df[\"piminus_P\"] * np.sin(all_df[\"piminus_ETA\"])\n",
    "        all_df[\"pminus_P_y0\"] = all_df[\"piminus_P\"] * np.cos(all_df[\"piminus_ETA\"])\n",
    "        all_df[\"B_PT_x\"] = all_df[\"B_PT\"] * all_df[\"B_DIRA_OWNPV\"]\n",
    "        all_df[\"B_PT_y\"] = all_df[\"B_PT\"] * all_df[\"B_DIRA_OWNPV_sin\"]\n",
    "        # Full p\n",
    "        # all_df[\"kp_x0_total\"] = all_df[\"Kplus_P_x0\"] + all_df[\"pminus_P_x0\"] + all_df[\"B_PT_x\"]\n",
    "        # all_df[\"kp_x_total\"] = all_df[\"Kplus_P_x\"] + all_df[\"pminus_P_x\"] + all_df[\"B_PT_x\"]\n",
    "        # all_df[\"kp_y0_total\"] = all_df[\"Kplus_P_y0\"] + all_df[\"pminus_P_y0\"] + all_df[\"B_PT_y\"]\n",
    "        # all_df[\"kp_y_total\"] = all_df[\"Kplus_P_y\"] + all_df[\"pminus_P_y\"] + all_df[\"B_PT_y\"]\n",
    "        # Paired p\n",
    "        all_df[\"kp_x0\"] = all_df[\"Kplus_P_x0\"] + all_df[\"pminus_P_x0\"]\n",
    "        all_df[\"kp_x\"] = all_df[\"Kplus_P_x\"] + all_df[\"pminus_P_x\"]\n",
    "        all_df[\"kp_y0\"] = all_df[\"Kplus_P_y0\"] + all_df[\"pminus_P_y0\"]\n",
    "        all_df[\"kp_y\"] = all_df[\"Kplus_P_y\"] + all_df[\"pminus_P_y\"]\n",
    "        all_df[\"kbx0\"] = all_df[\"Kplus_P_x0\"] + all_df[\"B_PT_x\"]\n",
    "        all_df[\"kb_x\"] = all_df[\"Kplus_P_x\"] + all_df[\"B_PT_x\"]\n",
    "        all_df[\"kby0\"] = all_df[\"Kplus_P_y0\"] + all_df[\"B_PT_y\"]\n",
    "        all_df[\"kb_y\"] = all_df[\"Kplus_P_y\"] + all_df[\"B_PT_y\"]\n",
    "        all_df[\"kp_x0_minus\"] = all_df[\"Kplus_P_x0\"] - all_df[\"pminus_P_x0\"]\n",
    "        all_df[\"kp_x_minus\"] = all_df[\"Kplus_P_x\"] - all_df[\"pminus_P_x\"]\n",
    "        all_df[\"kp_y0_minus\"] = all_df[\"Kplus_P_y0\"] - all_df[\"pminus_P_y0\"]\n",
    "        all_df[\"kp_y_minus\"] = all_df[\"Kplus_P_y\"] - all_df[\"pminus_P_y\"]\n",
    "        all_df[\"kbx0_minus\"] = all_df[\"Kplus_P_x0\"] - all_df[\"B_PT_x\"]\n",
    "        all_df[\"kb_x_minus\"] = all_df[\"Kplus_P_x\"] - all_df[\"B_PT_x\"]\n",
    "        all_df[\"kby0_minus\"] = all_df[\"Kplus_P_y0\"] - all_df[\"B_PT_y\"]\n",
    "        all_df[\"kb_y_minus\"] = all_df[\"Kplus_P_y\"] - all_df[\"B_PT_y\"]\n",
    "        all_df[\"kp_abs_x0\"] = np.abs(all_df[\"Kplus_P_x0\"]) + np.abs(\n",
    "            all_df[\"pminus_P_x0\"]\n",
    "        )\n",
    "        all_df[\"kp_abs_x\"] = np.abs(all_df[\"Kplus_P_x\"]) + np.abs(all_df[\"pminus_P_x\"])\n",
    "        all_df[\"kp_abs_y0\"] = np.abs(all_df[\"Kplus_P_y0\"]) + np.abs(\n",
    "            all_df[\"pminus_P_y0\"]\n",
    "        )\n",
    "        all_df[\"kp_abs_y\"] = np.abs(all_df[\"Kplus_P_y\"]) + np.abs(all_df[\"pminus_P_y\"])\n",
    "        # Full p ratio\n",
    "        all_df[\"kp_x0_ratio\"] = (all_df[\"Kplus_P_x0\"] + all_df[\"pminus_P_x0\"]) / all_df[\n",
    "            \"Kplus_P\"\n",
    "        ]\n",
    "        all_df[\"kp_x_ratio\"] = (all_df[\"Kplus_P_x\"] + all_df[\"pminus_P_x\"]) / all_df[\n",
    "            \"Kplus_P\"\n",
    "        ]\n",
    "        all_df[\"kp_y0_ratio\"] = (all_df[\"Kplus_P_y0\"] + all_df[\"pminus_P_y0\"]) / all_df[\n",
    "            \"Kplus_P\"\n",
    "        ]\n",
    "        all_df[\"kp_y_ratio\"] = (all_df[\"Kplus_P_y\"] + all_df[\"pminus_P_y\"]) / all_df[\n",
    "            \"Kplus_P\"\n",
    "        ]\n",
    "        all_df[\"kbx0_ratio\"] = (all_df[\"Kplus_P_x0\"] + all_df[\"B_PT_x\"]) / all_df[\n",
    "            \"Kplus_P\"\n",
    "        ]\n",
    "        all_df[\"kb_x_ratio\"] = (all_df[\"Kplus_P_x\"] + all_df[\"B_PT_x\"]) / all_df[\n",
    "            \"Kplus_P\"\n",
    "        ]\n",
    "        all_df[\"kby0_ratio\"] = (all_df[\"Kplus_P_y0\"] + all_df[\"B_PT_y\"]) / all_df[\n",
    "            \"Kplus_P\"\n",
    "        ]\n",
    "        all_df[\"kb_y_ratio\"] = (all_df[\"Kplus_P_y\"] + all_df[\"B_PT_y\"]) / all_df[\n",
    "            \"Kplus_P\"\n",
    "        ]\n",
    "        all_df[\"kp_x0_minus_ratio\"] = (\n",
    "            all_df[\"Kplus_P_x0\"] - all_df[\"pminus_P_x0\"]\n",
    "        ) / all_df[\"Kplus_P\"]\n",
    "        all_df[\"kp_x_minus_ratio\"] = (\n",
    "            all_df[\"Kplus_P_x\"] - all_df[\"pminus_P_x\"]\n",
    "        ) / all_df[\"Kplus_P\"]\n",
    "        all_df[\"kp_y0_minus_ratio\"] = (\n",
    "            all_df[\"Kplus_P_y0\"] - all_df[\"pminus_P_y0\"]\n",
    "        ) / all_df[\"Kplus_P\"]\n",
    "        all_df[\"kp_y_minus_ratio\"] = (\n",
    "            all_df[\"Kplus_P_y\"] - all_df[\"pminus_P_y\"]\n",
    "        ) / all_df[\"Kplus_P\"]\n",
    "        all_df[\"kbx0_minus_ratio\"] = (all_df[\"Kplus_P_x0\"] - all_df[\"B_PT_x\"]) / all_df[\n",
    "            \"Kplus_P\"\n",
    "        ]\n",
    "        all_df[\"kb_x_minus_ratio\"] = (all_df[\"Kplus_P_x\"] - all_df[\"B_PT_x\"]) / all_df[\n",
    "            \"Kplus_P\"\n",
    "        ]\n",
    "        all_df[\"kby0_minus_ratio\"] = (all_df[\"Kplus_P_y0\"] - all_df[\"B_PT_y\"]) / all_df[\n",
    "            \"Kplus_P\"\n",
    "        ]\n",
    "        all_df[\"kb_y_minus_ratio\"] = (all_df[\"Kplus_P_y\"] - all_df[\"B_PT_y\"]) / all_df[\n",
    "            \"Kplus_P\"\n",
    "        ]\n",
    "        # # things in hbar units\n",
    "        # all_df[\"B_hbar\"] = all_df[\"B_PT\"] * all_df[\"B_IPCHI2_OWNPV\"]\n",
    "        # all_df[\"B_hbar_2\"] = all_df[\"B_PT\"] * all_df[\"B_FDCHI2_OWNPV\"]\n",
    "        # all_df[\"K_hbar\"] = all_df[\"Kplus_P\"] * all_df[\"Kplus_IP_OWNPV\"]\n",
    "        # all_df[\"p_hbar\"] = all_df[\"piminus_P\"] * all_df[\"piminus_IP_OWNPV\"]\n",
    "        #\n",
    "        # # hbar ratios\n",
    "        # all_df[\"B_hbar_ratio\"] = all_df[\"B_hbar\"] / all_df[\"B_hbar_2\"]\n",
    "        # all_df[\"K_p_hbar_ratio\"] = all_df[\"K_hbar\"] / all_df[\"p_hbar\"]\n",
    "        # all_df[\"K_B_hbar_ratio\"] = all_df[\"K_hbar\"] / all_df[\"B_hbar\"]\n",
    "        # p ratios\n",
    "        all_df[\"gamma_B_PT_ratio\"] = all_df[\"gamma_PT\"] / all_df[\"B_PT\"]\n",
    "        all_df[\"piminus_B_P_ratio\"] = all_df[\"piminus_P\"] / all_df[\"B_PT\"]\n",
    "        # all_df[\"piminus_B_P_ratio_x\"] = (all_df[\"pminus_P_x\"] / all_df['B_PT'])\n",
    "        # all_df[\"piminus_B_P_ratio_y\"] = (all_df[\"pminus_P_y\"] / all_df['B_PT'])\n",
    "        all_df[\"kplus_B_P_ratio\"] = all_df[\"Kplus_P\"] / all_df[\"B_PT\"]\n",
    "        # all_df[\"kplus_B_P_ratio_x\"] = (all_df[\"Kplus_P_x\"] / all_df['B_PT'])\n",
    "        # all_df[\"kplus_B_P_ratio_y\"] = (all_df[\"Kplus_P_y\"] / all_df['B_PT'])\n",
    "        all_df[\"kplus_piminus_P_ratio\"] = all_df[\"Kplus_P\"] / all_df[\"piminus_P\"]\n",
    "        # distance ratios\n",
    "        all_df[\"b_distance_ratio\"] = all_df[\"B_IPCHI2_OWNPV\"] / all_df[\"B_FDCHI2_OWNPV\"]\n",
    "        all_df[\"k_p_distance_ratio\"] = (\n",
    "            all_df[\"Kplus_IP_OWNPV\"] / all_df[\"piminus_IP_OWNPV\"]\n",
    "        )\n",
    "        all_df[\"k_b_distance_ratio\"] = (\n",
    "            all_df[\"Kplus_IP_OWNPV\"] / all_df[\"B_IPCHI2_OWNPV\"]\n",
    "        )\n",
    "        all_df[\"p_b_distance_ratio\"] = (\n",
    "            all_df[\"piminus_IP_OWNPV\"] / all_df[\"B_IPCHI2_OWNPV\"]\n",
    "        )\n",
    "        all_df[\"k_kst_distance_ratio\"] = (\n",
    "            all_df[\"Kplus_IP_OWNPV\"] / all_df[\"Kst_892_0_IP_OWNPV\"]\n",
    "        )\n",
    "        # shpere radius\n",
    "        # all_df[\"sphere_radius_k_b\"] =  all_df['Kplus_IP_OWNPV']**2 + all_df['B_IPCHI2_OWNPV']**2\n",
    "        # all_df[\"sphere_radius_p_b\"] =  all_df['piminus_IP_OWNPV']**2 + all_df['B_IPCHI2_OWNPV']**2\n",
    "        # ANGLE ratios\n",
    "        # all_df[\"B_DIR\"] = np.arccos(all_df[\"B_DIRA_OWNPV\"])\n",
    "        # all_df[\"theta\"] = np.arccos(all_df[\"Kst_892_0_cosThetaH\"])\n",
    "        # all_df[\"angle_ratio\"] = np.log(all_df[\"B_DIR\"] / all_df[\"theta\"])\n",
    "        # all_df[\"b_eta\"] = np.arccos(all_df[\"B_DIRA_OWNPV\"])\n",
    "        # all_df[\"b_K_ratio\"] = all_df[\"b_eta\"] / all_df[\"Kplus_ETA\"]\n",
    "        # ETA ratio\n",
    "        all_df[\"eta_ratio\"] = all_df[\"Kplus_ETA\"] / all_df[\"piminus_ETA\"]\n",
    "        # Conservation of momentum\n",
    "        all_df[\"total_momentum\"] = (\n",
    "            all_df[\"gamma_PT\"]\n",
    "            + all_df[\"Kplus_P\"]\n",
    "            + all_df[\"piminus_P\"]\n",
    "            - all_df[\"B_PT\"]\n",
    "        )\n",
    "        all_df[\"total_momentum1\"] = (\n",
    "            all_df[\"gamma_PT\"]\n",
    "            - all_df[\"Kplus_P\"]\n",
    "            + all_df[\"piminus_P\"]\n",
    "            - all_df[\"B_PT\"]\n",
    "        )\n",
    "        all_df[\"total_momentum2\"] = (\n",
    "            all_df[\"gamma_PT\"]\n",
    "            + all_df[\"Kplus_P\"]\n",
    "            - all_df[\"piminus_P\"]\n",
    "            - all_df[\"B_PT\"]\n",
    "        )\n",
    "        all_df[\"total_momentum_sq\"] = (\n",
    "            all_df[\"gamma_PT\"] ** 2\n",
    "            + all_df[\"Kplus_P\"] ** 2\n",
    "            + all_df[\"piminus_P\"] ** 2\n",
    "            - all_df[\"B_PT\"] ** 2\n",
    "        )\n",
    "        all_df[\"total_momentum_x\"] = (\n",
    "            all_df[\"gamma_PT\"]\n",
    "            + all_df[\"Kplus_P_x\"]\n",
    "            + all_df[\"pminus_P_x\"]\n",
    "            - all_df[\"B_PT\"]\n",
    "        )\n",
    "        all_df[\"total_momentum_x2p\"] = (\n",
    "            all_df[\"gamma_PT\"]\n",
    "            + all_df[\"Kplus_P_x\"]\n",
    "            + 2 * all_df[\"pminus_P_x\"]\n",
    "            - all_df[\"B_PT\"]\n",
    "        )\n",
    "        all_df[\"total_momentum_x0\"] = (\n",
    "            all_df[\"gamma_PT\"]\n",
    "            + all_df[\"Kplus_P_x\"]\n",
    "            + all_df[\"pminus_P_x\"]\n",
    "            - all_df[\"B_PT\"]\n",
    "        )\n",
    "        all_df[\"total_momentum_x1\"] = (\n",
    "            all_df[\"gamma_PT\"]\n",
    "            - all_df[\"Kplus_P_x\"]\n",
    "            + all_df[\"pminus_P_x\"]\n",
    "            - all_df[\"B_PT\"]\n",
    "        )\n",
    "        all_df[\"total_momentum_x2\"] = (\n",
    "            all_df[\"gamma_PT\"]\n",
    "            + all_df[\"Kplus_P_x\"]\n",
    "            - all_df[\"pminus_P_x\"]\n",
    "            - all_df[\"B_PT\"]\n",
    "        )\n",
    "        all_df[\"total_momentum_y\"] = (\n",
    "            all_df[\"gamma_PT\"]\n",
    "            + all_df[\"Kplus_P_y\"]\n",
    "            + all_df[\"pminus_P_y\"]\n",
    "            - all_df[\"B_PT\"]\n",
    "        )\n",
    "        all_df[\"total_momentum_y2p\"] = (\n",
    "            all_df[\"gamma_PT\"]\n",
    "            + all_df[\"Kplus_P_y\"]\n",
    "            + 2 * all_df[\"pminus_P_y\"]\n",
    "            - all_df[\"B_PT\"]\n",
    "        )\n",
    "        all_df[\"total_momentum_y1\"] = (\n",
    "            all_df[\"gamma_PT\"]\n",
    "            - all_df[\"Kplus_P_y\"]\n",
    "            + all_df[\"pminus_P_y\"]\n",
    "            - all_df[\"B_PT\"]\n",
    "        )\n",
    "        all_df[\"total_momentum_y2\"] = (\n",
    "            all_df[\"gamma_PT\"]\n",
    "            + all_df[\"Kplus_P_y\"]\n",
    "            - all_df[\"pminus_P_y\"]\n",
    "            - all_df[\"B_PT\"]\n",
    "        )\n",
    "        all_df[\"total_momentum_abs\"] = np.abs(all_df[\"total_momentum\"])\n",
    "        all_df[\"total_momentum_x_abs\"] = np.abs(all_df[\"total_momentum_x\"])\n",
    "        all_df[\"total_momentum_y_abs\"] = np.abs(all_df[\"total_momentum_y\"])\n",
    "        # all_df[\"b_pi_dff_P_y\"] = 2 * all_df[\"pminus_P_y\"] - all_df[\"B_PT\"]\n",
    "        # all_df[\"b_pi_dff_P_x\"] = 2 * all_df[\"pminus_P_x\"] - all_df[\"B_PT\"]\n",
    "        all_df[\"total_momentum_K\"] = (\n",
    "            all_df[\"gamma_PT\"] + all_df[\"Kplus_P\"] - all_df[\"B_PT\"]\n",
    "        )\n",
    "        all_df[\"total_momentum_K_x\"] = (\n",
    "            all_df[\"gamma_PT\"] + all_df[\"Kplus_P_x\"] - all_df[\"B_PT_x\"]\n",
    "        )\n",
    "        all_df[\"total_momentum_K_y\"] = (\n",
    "            all_df[\"gamma_PT\"] + all_df[\"Kplus_P_y\"] - all_df[\"B_PT_y\"]\n",
    "        )\n",
    "        all_df[\"total_momentum_K_abs\"] = np.abs(all_df[\"total_momentum_K\"])\n",
    "        all_df[\"total_momentum_K_x_abs\"] = np.abs(all_df[\"total_momentum_K_x\"])\n",
    "        all_df[\"total_momentum_K_y_abs\"] = np.abs(all_df[\"total_momentum_K_y\"])\n",
    "        all_df[\"total_momentum_p\"] = (\n",
    "            all_df[\"gamma_PT\"] + all_df[\"piminus_P\"] - all_df[\"B_PT\"]\n",
    "        )\n",
    "        all_df[\"total_momentum_p_x\"] = (\n",
    "            all_df[\"gamma_PT\"] + all_df[\"pminus_P_x\"] - all_df[\"B_PT_x\"]\n",
    "        )\n",
    "        all_df[\"total_momentum_p_y\"] = (\n",
    "            all_df[\"gamma_PT\"] + all_df[\"pminus_P_y\"] - all_df[\"B_PT_y\"]\n",
    "        )\n",
    "        all_df[\"total_momentum_p_abs\"] = np.abs(all_df[\"total_momentum_p\"])\n",
    "        all_df[\"total_momentum_p_x_abs\"] = np.abs(all_df[\"total_momentum_p_x\"])\n",
    "        all_df[\"total_momentum_p_y_abs\"] = np.abs(all_df[\"total_momentum_p_y\"])\n",
    "\n",
    "        return all_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __shape__(self):\n",
    "        return self.X.shape[1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert idx from tensor to list due to pandas bug (that arises when using pytorch's random_split)\n",
    "        if isinstance(idx, torch.Tensor):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        return [self.X.iloc[idx].values, self.y[idx]]\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 6 * input_dim)\n",
    "        self.relu1 = nn.SELU()\n",
    "        self.batchnorm1 = nn.BatchNorm1d(6 * input_dim)\n",
    "        self.drop1 = nn.Dropout(0.05, inplace=False)\n",
    "\n",
    "        self.fc2 = nn.Linear(6 * input_dim, 3 * input_dim, bias=False)\n",
    "        self.relu2 = nn.SELU()\n",
    "        self.batchnorm2 = nn.BatchNorm1d(\n",
    "            3 * input_dim,\n",
    "            eps=1e-05,\n",
    "            momentum=0.1,\n",
    "            affine=True,\n",
    "            track_running_stats=True,\n",
    "        )\n",
    "        self.drop2 = nn.Dropout(0.05, inplace=False)\n",
    "\n",
    "        self.fc3 = nn.Linear(3 * input_dim, 2 * input_dim, bias=False)\n",
    "        self.relu3 = nn.SELU()\n",
    "        self.batchnorm3 = nn.BatchNorm1d(\n",
    "            2 * input_dim,\n",
    "            eps=1e-05,\n",
    "            momentum=0.1,\n",
    "            affine=True,\n",
    "            track_running_stats=True,\n",
    "        )\n",
    "        self.drop3 = nn.Dropout(0.05, inplace=False)\n",
    "\n",
    "        self.fc4 = nn.Linear(2 * input_dim, 1 * input_dim, bias=False)\n",
    "        self.relu4 = nn.SELU()\n",
    "        self.batchnorm4 = nn.BatchNorm1d(\n",
    "            input_dim, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
    "        )\n",
    "        self.drop4 = nn.Dropout(0.05, inplace=False)\n",
    "\n",
    "        self.fc5 = nn.Linear(input_dim, 1, bias=True)\n",
    "\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        self.batchnorm1(x)\n",
    "        self.drop1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        self.batchnorm2(x)\n",
    "        self.drop2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        self.batchnorm3(x)\n",
    "        self.drop3(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "        self.batchnorm4(x)\n",
    "        self.drop4(x)\n",
    "\n",
    "        x = self.fc5(x)\n",
    "        x = self.sig(x)\n",
    "\n",
    "        return x.squeeze()\n",
    "\n",
    "    def step(self, inputs):\n",
    "        data, label = inputs  # ignore label\n",
    "        outputs = self.forward(data)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        # preds, outputs  are cuda tensors. Right?\n",
    "        return preds, outputs\n",
    "\n",
    "    def predict_proba(self, data):\n",
    "        # Pass the NN forward\n",
    "        out = self.forward(data)\n",
    "\n",
    "        # Transform to\n",
    "        return out.detach().numpy().squeeze()\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 6 * input_dim)\n",
    "        self.relu1 = nn.SELU()\n",
    "        self.batchnorm1 = nn.BatchNorm1d(6 * input_dim)\n",
    "        self.drop1 = nn.Dropout(0.05, inplace=False)\n",
    "\n",
    "        self.fc2 = nn.Linear(6 * input_dim, 3 * input_dim, bias=False)\n",
    "        self.relu2 = nn.SELU()\n",
    "        self.batchnorm2 = nn.BatchNorm1d(\n",
    "            3 * input_dim ,\n",
    "            eps=1e-05,\n",
    "            momentum=0.1,\n",
    "            affine=True,\n",
    "            track_running_stats=True,\n",
    "        )\n",
    "        self.drop2 = nn.Dropout(0.05, inplace=False)\n",
    "\n",
    "        self.fc3 = nn.Linear(3 * input_dim, 2 * input_dim, bias=False)\n",
    "        self.relu3 = nn.SELU()\n",
    "        self.batchnorm3 = nn.BatchNorm1d(\n",
    "            2 * input_dim+ input_dim,\n",
    "            eps=1e-05,\n",
    "            momentum=0.1,\n",
    "            affine=True,\n",
    "            track_running_stats=True,\n",
    "        )\n",
    "        self.drop3 = nn.Dropout(0.05, inplace=False)\n",
    "\n",
    "        self.fc4 = nn.Linear(2 * input_dim+ input_dim, 1 * input_dim, bias=False)\n",
    "        self.relu4 = nn.SELU()\n",
    "        self.batchnorm4 = nn.BatchNorm1d(\n",
    "            input_dim, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
    "        )\n",
    "        self.drop4 = nn.Dropout(0.05, inplace=False)\n",
    "\n",
    "        self.fc5 = nn.Linear(input_dim, 1, bias=True)\n",
    "\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = x\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        self.batchnorm1(x)\n",
    "        self.drop1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        self.batchnorm2(x)\n",
    "        self.drop2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(torch.cat((x, x1), 1))\n",
    "        self.batchnorm3(x)\n",
    "        self.drop3(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "        self.batchnorm4(x)\n",
    "        self.drop4(x)\n",
    "\n",
    "        x = self.fc5(x)\n",
    "        x = self.sig(x)\n",
    "\n",
    "        return x.squeeze()\n",
    "\n",
    "    def step(self, inputs):\n",
    "        data, label = inputs  # ignore label\n",
    "        outputs = self.forward(data)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        # preds, outputs  are cuda tensors. Right?\n",
    "        return preds, outputs\n",
    "\n",
    "    def predict_proba(self, data):\n",
    "        # Pass the NN forward\n",
    "        out = self.forward(data)\n",
    "\n",
    "        # Transform to\n",
    "        return out.detach().numpy().squeeze()\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, siz3, downsample=None):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(size, 2 * size)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(2 * size)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(2 * size, size)\n",
    "        self.bn2 = nn.BatchNorm1d(size)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.fc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.fc2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _make_layer(block, inplanes, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or inplanes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(inplanes, planes, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(inplanes, planes, stride, downsample))\n",
    "        inplanes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "(159496, 182)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1342: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159496, 582)\n",
      "---\n",
      "(53166, 182)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1342: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53166, 580)\n",
      "(159496, 582)\n",
      "(53166, 580)\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def evaluate_auc(model, data, label):\n",
    "    return roc_auc_score(label.detach().numpy(), model(data.float()).detach().numpy())\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "# Read data\n",
    "train_file = \"train_split.csv\"\n",
    "validation_file = \"valid_split.csv\"\n",
    "trainset = ReadDataset(train_file)\n",
    "testset = ReadDataset(validation_file)\n",
    "\n",
    "# Data loaders\n",
    "trainloader = DataLoader(trainset, batch_size=100, shuffle=True)\n",
    "\n",
    "# Test set\n",
    "X_test = torch.tensor(testset.X.values)\n",
    "y_test = torch.tensor(testset.y.values)\n",
    "print(trainset.X.shape)\n",
    "print(testset.X.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Neural Network\n",
    "nnet = ResNet(trainset.__shape__()).to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(\n",
    "    nnet.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.000001\n",
    ")\n",
    "\n",
    "\n",
    "# Train the net\n",
    "loss_per_iter = []\n",
    "loss_per_batch = []\n",
    "\n",
    "\n",
    "# Train the net\n",
    "losses = []\n",
    "auc_train = []\n",
    "auc_test = []\n",
    "\n",
    "# hyperparameteres\n",
    "n_epochs = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "(159496, 182)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1342: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159496, 582)\n",
      "---\n",
      "(53166, 182)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1342: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53166, 580)\n",
      "(159496, 582)\n",
      "(53166, 580)\n",
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [53166 x 580], m2: [582 x 3492] at /Users/distiller/project/conda/conda-bld/pytorch_1595629430416/work/aten/src/TH/generic/THTensorMath.cpp:41",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2865f91d3ce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mauc_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mauc_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# Figure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-2865f91d3ce8>\u001b[0m in \u001b[0;36mevaluate_auc\u001b[0;34m(model, data, label)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7efebddcad5d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [53166 x 580], m2: [582 x 3492] at /Users/distiller/project/conda/conda-bld/pytorch_1595629430416/work/aten/src/TH/generic/THTensorMath.cpp:41"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(epoch)\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        X = inputs.to(device)\n",
    "        y = labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forwarde\n",
    "        outputs = nnet(X.float())\n",
    "\n",
    "        # Compute diff\n",
    "        loss = criterion(outputs, y.float())\n",
    "\n",
    "        # Compute gradient\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save loss to plot\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            auc_train.append(evaluate_auc(nnet, X.float(), y.float()))\n",
    "            auc_test.append(evaluate_auc(nnet, X_test, y_test))\n",
    "\n",
    "            # Figure\n",
    "            plt.figure()\n",
    "            plt.ylim([0.6, 1])\n",
    "            plt.plot(auc_test, label=\"test\")\n",
    "            plt.plot(auc_train, label=\"train\")\n",
    "            plt.legend()\n",
    "            plt.savefig(\"output/auc_NN.png\")\n",
    "            plt.savefig(\"output/auc_NN.svg\", format=\"svg\")\n",
    "            plt.close()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        path = \"output/weights\" + str(epoch) + \".pt\"\n",
    "        torch.save(nnet.state_dict(), path)\n",
    "\n",
    "torch.save(nnet.state_dict(), \"output/weights_final.pt\")\n",
    "toc = time.time()\n",
    "elap_time = np.round(np.abs(tic - toc), 1)\n",
    "print(\"Elapsed time: \", elap_time)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingFeatureGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1342: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingFeatureGenerator(add_probs=False, criterion='friedman_mse',\n",
       "                                 init=None, learning_rate=0.1, loss='deviance',\n",
       "                                 max_depth=3, max_features=None,\n",
       "                                 max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                                 min_impurity_split=None, min_samples_leaf=1,\n",
       "                                 min_samples_split=2,\n",
       "                                 min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                                 n_iter_no_change=None, presort='auto',\n",
       "                                 random_state=None, sparse_feat=False,\n",
       "                                 stack_to_X=True, subsample=1.0, tol=0.0001,\n",
       "                                 validation_fraction=0.1, verbose=0,\n",
       "                                 warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.fit(trainset.X.head(10),trainset.y.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 682)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.transform(trainset.X.head(100)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 682)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.transform(trainset.X.tail(10)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
