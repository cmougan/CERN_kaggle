{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from nnet import ReadDataset, Net\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def evaluate_auc(model, data, label):\n",
    "    return roc_auc_score(label.detach().numpy(), model(data.float()).detach().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = os.path.join(sys.path[0], \"train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212662, 98)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "dataset = ReadDataset(csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.SELU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "4\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Hola at 0x7fe3c6aaab50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Hola():\n",
    "    def __init__(self):\n",
    "        print('a')\n",
    "        self.var = 4\n",
    "        print(self.var)\n",
    "        self.var +1\n",
    "        print(self.var)\n",
    "Hola()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Net:\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([154, 77]) from checkpoint, the shape in current model is torch.Size([196, 98]).\n\tsize mismatch for fc1.bias: copying a param with shape torch.Size([154]) from checkpoint, the shape in current model is torch.Size([196]).\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([231, 154]) from checkpoint, the shape in current model is torch.Size([294, 196]).\n\tsize mismatch for fc2.bias: copying a param with shape torch.Size([231]) from checkpoint, the shape in current model is torch.Size([294]).\n\tsize mismatch for fc3.weight: copying a param with shape torch.Size([154, 231]) from checkpoint, the shape in current model is torch.Size([196, 294]).\n\tsize mismatch for fc3.bias: copying a param with shape torch.Size([154]) from checkpoint, the shape in current model is torch.Size([196]).\n\tsize mismatch for fc4.weight: copying a param with shape torch.Size([77, 154]) from checkpoint, the shape in current model is torch.Size([98, 196]).\n\tsize mismatch for fc4.bias: copying a param with shape torch.Size([77]) from checkpoint, the shape in current model is torch.Size([98]).\n\tsize mismatch for fc5.weight: copying a param with shape torch.Size([1, 77]) from checkpoint, the shape in current model is torch.Size([1, 98]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-a20accdbdca2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__shape__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output/weights80.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1045\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Net:\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([154, 77]) from checkpoint, the shape in current model is torch.Size([196, 98]).\n\tsize mismatch for fc1.bias: copying a param with shape torch.Size([154]) from checkpoint, the shape in current model is torch.Size([196]).\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([231, 154]) from checkpoint, the shape in current model is torch.Size([294, 196]).\n\tsize mismatch for fc2.bias: copying a param with shape torch.Size([231]) from checkpoint, the shape in current model is torch.Size([294]).\n\tsize mismatch for fc3.weight: copying a param with shape torch.Size([154, 231]) from checkpoint, the shape in current model is torch.Size([196, 294]).\n\tsize mismatch for fc3.bias: copying a param with shape torch.Size([154]) from checkpoint, the shape in current model is torch.Size([196]).\n\tsize mismatch for fc4.weight: copying a param with shape torch.Size([77, 154]) from checkpoint, the shape in current model is torch.Size([98, 196]).\n\tsize mismatch for fc4.bias: copying a param with shape torch.Size([77]) from checkpoint, the shape in current model is torch.Size([98]).\n\tsize mismatch for fc5.weight: copying a param with shape torch.Size([1, 77]) from checkpoint, the shape in current model is torch.Size([1, 98])."
     ]
    }
   ],
   "source": [
    "# Use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Neural Network\n",
    "nnet = Net(dataset.__shape__()).to(device)\n",
    "\n",
    "nnet.load_state_dict(torch.load(\"output/weights80.pt\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>B_OWNPV_CHI2</th>\n",
       "      <th>B_IPCHI2_OWNPV</th>\n",
       "      <th>B_FDCHI2_OWNPV</th>\n",
       "      <th>B_DIRA_OWNPV</th>\n",
       "      <th>B_PT</th>\n",
       "      <th>Kst_892_0_IP_OWNPV</th>\n",
       "      <th>Kst_892_0_cosThetaH</th>\n",
       "      <th>Kplus_IP_OWNPV</th>\n",
       "      <th>Kplus_P</th>\n",
       "      <th>...</th>\n",
       "      <th>ETA_add</th>\n",
       "      <th>ETA_rest</th>\n",
       "      <th>ETA_mult</th>\n",
       "      <th>ETA_inv</th>\n",
       "      <th>ETA_inv1</th>\n",
       "      <th>ETA_add_inv</th>\n",
       "      <th>ETA_rest_inv</th>\n",
       "      <th>ETA_mult_inv</th>\n",
       "      <th>ETA_inv_inv</th>\n",
       "      <th>ETA_inv1_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265841</td>\n",
       "      <td>0.332817</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.994004</td>\n",
       "      <td>0.308120</td>\n",
       "      <td>0.131881</td>\n",
       "      <td>0.124717</td>\n",
       "      <td>0.119922</td>\n",
       "      <td>0.655479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257499</td>\n",
       "      <td>0.526203</td>\n",
       "      <td>0.184740</td>\n",
       "      <td>0.482033</td>\n",
       "      <td>0.379137</td>\n",
       "      <td>0.257499</td>\n",
       "      <td>0.526203</td>\n",
       "      <td>0.184740</td>\n",
       "      <td>0.482033</td>\n",
       "      <td>0.379137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.315485</td>\n",
       "      <td>0.011589</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.994359</td>\n",
       "      <td>0.076741</td>\n",
       "      <td>0.017397</td>\n",
       "      <td>0.102251</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.368834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473501</td>\n",
       "      <td>0.376905</td>\n",
       "      <td>0.378018</td>\n",
       "      <td>0.336657</td>\n",
       "      <td>0.528249</td>\n",
       "      <td>0.473501</td>\n",
       "      <td>0.376905</td>\n",
       "      <td>0.378018</td>\n",
       "      <td>0.336657</td>\n",
       "      <td>0.528249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.332915</td>\n",
       "      <td>0.305303</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.972899</td>\n",
       "      <td>0.097357</td>\n",
       "      <td>0.007981</td>\n",
       "      <td>0.582989</td>\n",
       "      <td>0.035285</td>\n",
       "      <td>0.249116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509310</td>\n",
       "      <td>0.316212</td>\n",
       "      <td>0.412749</td>\n",
       "      <td>0.287263</td>\n",
       "      <td>0.585065</td>\n",
       "      <td>0.509310</td>\n",
       "      <td>0.316212</td>\n",
       "      <td>0.412749</td>\n",
       "      <td>0.287263</td>\n",
       "      <td>0.585065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.130552</td>\n",
       "      <td>0.792201</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.611310</td>\n",
       "      <td>0.078767</td>\n",
       "      <td>0.052622</td>\n",
       "      <td>0.773269</td>\n",
       "      <td>0.056236</td>\n",
       "      <td>0.070704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092701</td>\n",
       "      <td>0.443708</td>\n",
       "      <td>0.060586</td>\n",
       "      <td>0.377261</td>\n",
       "      <td>0.484026</td>\n",
       "      <td>0.092701</td>\n",
       "      <td>0.443708</td>\n",
       "      <td>0.060586</td>\n",
       "      <td>0.377261</td>\n",
       "      <td>0.484026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.558763</td>\n",
       "      <td>0.954103</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.810036</td>\n",
       "      <td>0.056773</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.808806</td>\n",
       "      <td>0.030653</td>\n",
       "      <td>0.083261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512606</td>\n",
       "      <td>0.491624</td>\n",
       "      <td>0.417578</td>\n",
       "      <td>0.442995</td>\n",
       "      <td>0.416759</td>\n",
       "      <td>0.512606</td>\n",
       "      <td>0.491624</td>\n",
       "      <td>0.417578</td>\n",
       "      <td>0.442995</td>\n",
       "      <td>0.416759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212657</th>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.306550</td>\n",
       "      <td>0.052857</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.998048</td>\n",
       "      <td>0.075184</td>\n",
       "      <td>0.044315</td>\n",
       "      <td>0.223672</td>\n",
       "      <td>0.051462</td>\n",
       "      <td>0.483762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461952</td>\n",
       "      <td>0.592427</td>\n",
       "      <td>0.366988</td>\n",
       "      <td>0.542661</td>\n",
       "      <td>0.323842</td>\n",
       "      <td>0.461952</td>\n",
       "      <td>0.592427</td>\n",
       "      <td>0.366988</td>\n",
       "      <td>0.542661</td>\n",
       "      <td>0.323842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212658</th>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.279994</td>\n",
       "      <td>0.854825</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.818340</td>\n",
       "      <td>0.076798</td>\n",
       "      <td>0.030936</td>\n",
       "      <td>0.734470</td>\n",
       "      <td>0.030138</td>\n",
       "      <td>0.293401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622031</td>\n",
       "      <td>0.550067</td>\n",
       "      <td>0.532474</td>\n",
       "      <td>0.494084</td>\n",
       "      <td>0.367851</td>\n",
       "      <td>0.622031</td>\n",
       "      <td>0.550067</td>\n",
       "      <td>0.532474</td>\n",
       "      <td>0.494084</td>\n",
       "      <td>0.367851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212659</th>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.072541</td>\n",
       "      <td>0.282106</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.756086</td>\n",
       "      <td>0.049421</td>\n",
       "      <td>0.152253</td>\n",
       "      <td>0.346480</td>\n",
       "      <td>0.123860</td>\n",
       "      <td>0.129636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225870</td>\n",
       "      <td>0.723514</td>\n",
       "      <td>0.156972</td>\n",
       "      <td>0.738737</td>\n",
       "      <td>0.167350</td>\n",
       "      <td>0.225870</td>\n",
       "      <td>0.723514</td>\n",
       "      <td>0.156972</td>\n",
       "      <td>0.738737</td>\n",
       "      <td>0.167350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212660</th>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.547748</td>\n",
       "      <td>0.423147</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.655940</td>\n",
       "      <td>0.130150</td>\n",
       "      <td>0.028006</td>\n",
       "      <td>0.971249</td>\n",
       "      <td>0.038650</td>\n",
       "      <td>0.078148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128985</td>\n",
       "      <td>0.510865</td>\n",
       "      <td>0.086248</td>\n",
       "      <td>0.466430</td>\n",
       "      <td>0.393977</td>\n",
       "      <td>0.128985</td>\n",
       "      <td>0.510865</td>\n",
       "      <td>0.086248</td>\n",
       "      <td>0.466430</td>\n",
       "      <td>0.393977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212661</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.208908</td>\n",
       "      <td>0.962318</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.421156</td>\n",
       "      <td>0.229796</td>\n",
       "      <td>0.017091</td>\n",
       "      <td>0.355639</td>\n",
       "      <td>0.042443</td>\n",
       "      <td>0.844509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671173</td>\n",
       "      <td>0.494145</td>\n",
       "      <td>0.587230</td>\n",
       "      <td>0.445555</td>\n",
       "      <td>0.414241</td>\n",
       "      <td>0.671173</td>\n",
       "      <td>0.494145</td>\n",
       "      <td>0.587230</td>\n",
       "      <td>0.445555</td>\n",
       "      <td>0.414241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212662 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id  B_OWNPV_CHI2  B_IPCHI2_OWNPV  B_FDCHI2_OWNPV  B_DIRA_OWNPV  \\\n",
       "0       0.000000      0.265841        0.332817        0.001468      0.994004   \n",
       "1       0.000005      0.315485        0.011589        0.000160      0.994359   \n",
       "2       0.000009      0.332915        0.305303        0.000105      0.972899   \n",
       "3       0.000014      0.130552        0.792201        0.000099      0.611310   \n",
       "4       0.000019      0.558763        0.954103        0.000038      0.810036   \n",
       "...          ...           ...             ...             ...           ...   \n",
       "212657  0.999981      0.306550        0.052857        0.000252      0.998048   \n",
       "212658  0.999986      0.279994        0.854825        0.000109      0.818340   \n",
       "212659  0.999991      0.072541        0.282106        0.000176      0.756086   \n",
       "212660  0.999995      0.547748        0.423147        0.000327      0.655940   \n",
       "212661  1.000000      0.208908        0.962318        0.000129      0.421156   \n",
       "\n",
       "            B_PT  Kst_892_0_IP_OWNPV  Kst_892_0_cosThetaH  Kplus_IP_OWNPV  \\\n",
       "0       0.308120            0.131881             0.124717        0.119922   \n",
       "1       0.076741            0.017397             0.102251        0.049505   \n",
       "2       0.097357            0.007981             0.582989        0.035285   \n",
       "3       0.078767            0.052622             0.773269        0.056236   \n",
       "4       0.056773            0.001525             0.808806        0.030653   \n",
       "...          ...                 ...                  ...             ...   \n",
       "212657  0.075184            0.044315             0.223672        0.051462   \n",
       "212658  0.076798            0.030936             0.734470        0.030138   \n",
       "212659  0.049421            0.152253             0.346480        0.123860   \n",
       "212660  0.130150            0.028006             0.971249        0.038650   \n",
       "212661  0.229796            0.017091             0.355639        0.042443   \n",
       "\n",
       "         Kplus_P  ...   ETA_add  ETA_rest  ETA_mult   ETA_inv  ETA_inv1  \\\n",
       "0       0.655479  ...  0.257499  0.526203  0.184740  0.482033  0.379137   \n",
       "1       0.368834  ...  0.473501  0.376905  0.378018  0.336657  0.528249   \n",
       "2       0.249116  ...  0.509310  0.316212  0.412749  0.287263  0.585065   \n",
       "3       0.070704  ...  0.092701  0.443708  0.060586  0.377261  0.484026   \n",
       "4       0.083261  ...  0.512606  0.491624  0.417578  0.442995  0.416759   \n",
       "...          ...  ...       ...       ...       ...       ...       ...   \n",
       "212657  0.483762  ...  0.461952  0.592427  0.366988  0.542661  0.323842   \n",
       "212658  0.293401  ...  0.622031  0.550067  0.532474  0.494084  0.367851   \n",
       "212659  0.129636  ...  0.225870  0.723514  0.156972  0.738737  0.167350   \n",
       "212660  0.078148  ...  0.128985  0.510865  0.086248  0.466430  0.393977   \n",
       "212661  0.844509  ...  0.671173  0.494145  0.587230  0.445555  0.414241   \n",
       "\n",
       "        ETA_add_inv  ETA_rest_inv  ETA_mult_inv  ETA_inv_inv  ETA_inv1_inv  \n",
       "0          0.257499      0.526203      0.184740     0.482033      0.379137  \n",
       "1          0.473501      0.376905      0.378018     0.336657      0.528249  \n",
       "2          0.509310      0.316212      0.412749     0.287263      0.585065  \n",
       "3          0.092701      0.443708      0.060586     0.377261      0.484026  \n",
       "4          0.512606      0.491624      0.417578     0.442995      0.416759  \n",
       "...             ...           ...           ...          ...           ...  \n",
       "212657     0.461952      0.592427      0.366988     0.542661      0.323842  \n",
       "212658     0.622031      0.550067      0.532474     0.494084      0.367851  \n",
       "212659     0.225870      0.723514      0.156972     0.738737      0.167350  \n",
       "212660     0.128985      0.510865      0.086248     0.466430      0.393977  \n",
       "212661     0.671173      0.494145      0.587230     0.445555      0.414241  \n",
       "\n",
       "[212662 rows x 98 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9019872270502004"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(dataset.X.values)\n",
    "a = a.to(device).float()\n",
    "\n",
    "\n",
    "\n",
    "a = nnet.forward(a)\n",
    "\n",
    "\n",
    "a = a.detach().numpy()\n",
    "\n",
    "b = dataset.y.values\n",
    "\n",
    "roc_auc_score(b,a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212662, 98)\n",
      "(141776, 98)\n"
     ]
    }
   ],
   "source": [
    "#Read data\n",
    "dataset = ReadDataset(csv_file,for_test=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141776, 98)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tensor(dataset.X).to(device).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = nnet.forward(test)\n",
    "\n",
    "test_out = test_out.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44615906, 0.44557956, 0.44481114, ..., 0.4458449 , 0.44527072,\n",
       "       0.44447246], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = pd.read_csv(\"test.csv\", index_col=\"Id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T06:21:59.073057Z",
     "start_time": "2020-10-25T06:21:58.960955Z"
    }
   },
   "outputs": [],
   "source": [
    "test['Predicted'] = test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T06:22:16.547088Z",
     "start_time": "2020-10-25T06:22:16.121399Z"
    }
   },
   "outputs": [],
   "source": [
    "test[['Predicted']].to_csv('submissions/nn_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'getset_descriptor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-0bb45c04e8ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'getset_descriptor' object is not callable"
     ]
    }
   ],
   "source": [
    "datetime.day()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
